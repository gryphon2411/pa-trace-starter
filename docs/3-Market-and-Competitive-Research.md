# Prior Authorization for Imaging: Payer Criteria, Data Examples, Tools, and Demo Architecture

## 1\. Clinical Criteria for Imaging – Payer Policies (Aetna, Cigna, CMS, NHS)

**U.S. Payers (Aetna, Cigna, Medicare):** Major insurers generally require that advanced imaging (MRI/CT) of the spine meet specific medical necessity criteria before approving a prior authorization (PA). For example, Aetna’s policy for spine MRI/CT deems it **“medically necessary”** only if certain conditions are met – such as clear clinical evidence of serious pathology or failure of conservative management. One key criterion is often **persistent back or neck pain with neurological findings that has not improved after \~6 weeks of conservative therapy** (e.g. prescribed moderate activity, NSAIDs, muscle relaxants), *unless* red-flag symptoms are present[\[1\]](https://www.aetna.com/cpb/medical/data/200_299/0236.html#:~:text=malignant%29%3B%C2%A0or%20,deficit%2C%20or%20major%20motor%20weakness%3B%C2%A0or)[\[2\]](https://www.evicore.com/sites/default/files/clinical-guidelines/2024-11/Cigna_Spine%20Imaging%20Guidelines_V1.1.2025_Eff02.14.2025_pub11.27.2024.pdf#:~:text=Multiple%20studies%20have%20shown%20most,rate%20of%20imaging%20with%20the). In other words, most policies insist on a trial of nonsurgical treatment (physical therapy, medications, etc.) for a defined period (commonly 4–6 weeks) prior to imaging, barring urgent indications. For instance, Aetna explicitly requires **“no improvement after 6 weeks of conservative therapy”** for chronic radicular back pain before MRI is covered[\[1\]](https://www.aetna.com/cpb/medical/data/200_299/0236.html#:~:text=malignant%29%3B%C2%A0or%20,deficit%2C%20or%20major%20motor%20weakness%3B%C2%A0or). Cigna’s musculoskeletal imaging guidelines (administered via eviCore) echo this: *“most patients with acute neck or back pain will improve with 6 weeks of conservative care; however, conservative care is not required for patients with red flag indications”*[\[2\]](https://www.evicore.com/sites/default/files/clinical-guidelines/2024-11/Cigna_Spine%20Imaging%20Guidelines_V1.1.2025_Eff02.14.2025_pub11.27.2024.pdf#:~:text=Multiple%20studies%20have%20shown%20most,rate%20of%20imaging%20with%20the). Red flags (e.g. suspected spinal cord compression, severe/progressive neurologic deficit, infection, malignancy) are generally listed as automatic approval conditions without conservative-treatment delay[\[3\]](https://www.aetna.com/cpb/medical/data/200_299/0236.html#:~:text=,location%20for%20performing%20the%20injection%3B%C2%A0or)[\[1\]](https://www.aetna.com/cpb/medical/data/200_299/0236.html#:~:text=malignant%29%3B%C2%A0or%20,deficit%2C%20or%20major%20motor%20weakness%3B%C2%A0or). Medicare’s approach differs slightly – **CMS (Medicare)** historically attempted an Appropriate Use Criteria (AUC) program instead of prior auth, requiring clinicians to consult evidence-based imaging guidelines for high-cost scans. (This AUC program was meant to improve appropriate MRI/CT ordering as an *alternative* to PA, but was indefinitely **paused in 2023** due to implementation challenges[\[4\]](https://www.mcg.com/blog/cms-appropriate-use-criteria-auc-imaging/#:~:text=First%20established%20by%20the%20Protecting,a%20Medicare%20beneficiary%20would%20be)[\[5\]](https://www.mcg.com/blog/cms-appropriate-use-criteria-auc-imaging/#:~:text=An%20Indefinite%20Pause%20on%20AUC).) In practice, **Medicare Advantage** plans follow similar PA rules as other insurers, whereas traditional Medicare relies on coverage policies and clinician attestation of medical necessity.

**NHS (UK) and Global:** In the UK’s National Health Service, there is no insurer “prior authorization” process; however, clinical guidelines play a similar gatekeeping role. **NICE guidelines and NHS referral criteria** for imaging strongly discourage early scans for low back pain without serious signs. For example, local NHS pathways state: **“Do not routinely offer imaging for back pain in the absence of red flags… routine imaging is NOT warranted… unless serious underlying pathology is suspected.”**[\[6\]](https://www.coventryrugbygpgateway.nhs.uk/pages/management-of-neck-back-pain/#:~:text=Do%20NOT%20offer%20r%20outine,the%20absence%20of%20red%20flags). Patients are typically managed conservatively for several weeks (with advice, pain management, physiotherapy) before any MRI is considered. Only if red flag features emerge (e.g. cauda equina syndrome, cancer, fracture, infection) is immediate imaging indicated, mirroring the utilization management criteria seen in U.S. payers. In summary, across both U.S. and international guidelines, a common policy element is: **require evidence of an appropriate clinical indication – usually either “X weeks of conservative therapy without improvement” or a recognized urgent/red-flag condition – before approving advanced imaging**[\[1\]](https://www.aetna.com/cpb/medical/data/200_299/0236.html#:~:text=malignant%29%3B%C2%A0or%20,deficit%2C%20or%20major%20motor%20weakness%3B%C2%A0or)[\[7\]](https://bsw.icb.nhs.uk/wp-content/uploads/sites/6/2023/09/BSW-ICB-CP039-Spinal-pain-Neck-and-lower-back.pdf#:~:text=or%20back%20pain%20with%20radiculopathy,OR). This ensures imaging is used judiciously and only when it is likely to impact patient management.

## 2\. Standard Fields on Prior Authorization Forms for Imaging

Prior authorization request forms for imaging exams (MRI, CT, etc.) have a **consistent set of required fields** that collect patient info, clinical details, and justification for the test. These forms are often structured with sections covering:

* **Patient and Insurance Information:** Patient’s name, date of birth, insurance plan, member ID, group number, etc.[\[8\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=SECTION%201,Name%3A%20Facility%20Tax%20ID%3A%20NPI).

* **Requesting Provider Details:** Ordering physician’s name, specialty, NPI, contact information (phone, fax), and often the referring provider’s details if different[\[9\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=SECTION%202,EXAM%20REQUEST).

* **Service/Facility Details:** The facility or imaging center where the scan will be done, facility ID or NPI, address, and the proposed date of service[\[10\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=Phone%20,EXAM%20REQUEST).

* **Exam Requested:** The specific imaging modality and body area. Forms typically have checkboxes for CT, MRI, etc., and require CPT code(s) for the procedure and a written description (e.g. “Lumbar spine MRI without contrast”)[\[11\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=%E2%98%90%20CT%20%E2%98%90%20MRI%20%E2%98%90,CHECK%20ALL%20THAT%20APPLY).

* **Diagnosis Information:** The relevant diagnosis or clinical suspicion prompting the study. An ICD-10 diagnosis code is usually required, along with a brief description of the condition (e.g. “M54.5 – Low back pain”)[\[11\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=%E2%98%90%20CT%20%E2%98%90%20MRI%20%E2%98%90,CHECK%20ALL%20THAT%20APPLY).

* **Clinical Indications/Reason for Study:** A checklist or free-text field to indicate why the imaging is needed. Many PA forms for imaging list common indications as checkboxes. For example, a spine MRI section might include options such as “☑ Radiculopathy (nerve root symptoms)”, “☑ Persistent pain ≥6 weeks”, “☑ Trauma or acute injury”, “☑ Known or suspected tumor”, “☑ Neurological deficits”, etc.[\[12\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=%E2%98%90%20SPINE%20%E2%98%90%20Neurological%20Deficits,ray). The requester checks all that apply, demonstrating the exam’s necessity (especially highlighting any red-flag conditions or prior tests that support the need).

* **Prior Treatments and Duration of Symptoms:** This is critical for imaging PAs. Forms will ask how long the patient has had symptoms and what conservative treatments have been tried. A common format is a combination of **duration** and **modality** of prior therapy. For example, the form may require the clinician to **“Check one: ☐ No prior treatment, ☐ 3–5 weeks of treatment, ☐ 6 or more weeks of treatment”** and then **“Check all treatments that apply: ☐ NSAIDs, ☐ Physical Therapy, ☐ Spine injections, ☐ Chiropractic care, ☐ Home exercise, ☐ Oral steroids,”** etc.[\[13\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=Check%20One%20,Exercise%20Program%20%E2%98%90%20Physical%20Therapy). This captures whether the patient completed the guideline-recommended conservative management period (e.g. at least 6 weeks) and which therapies were attempted.

* **Previous Imaging or Tests:** Many forms include fields to note any prior imaging studies or relevant tests. For instance: *“X-ray done? ☐ Yes (date:\_\_\_) ☐ No”*, or fields to list prior MRI/CT results, EMG findings, etc., if applicable. This helps the payer see that duplicate imaging isn’t being ordered and that work-up is appropriate.

* **Clinical Findings and Notes:** A free-text section or attachment area is often provided for additional clinical details. For example, the provider can document exam findings (e.g. motor weakness, reflex changes), severity of pain, or attach clinical notes. Some forms explicitly say **“Include relevant clinical documentation of conservative therapy duration, prior imaging, and any trauma history”** as part of the submission[\[14\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=implants%2C%20for%20detection%20of%20implant,birads3).

In summary, a PA form for imaging will require **patient and provider IDs, the exam codes, diagnosis, clinical justification with checkboxes, duration of symptoms/treatment, and documentation of any prior therapies or studies**. The Massachusetts state **standardized CT/MRI prior auth form** is a good example – it prompts for all the above fields in a structured way[\[11\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=%E2%98%90%20CT%20%E2%98%90%20MRI%20%E2%98%90,CHECK%20ALL%20THAT%20APPLY)[\[15\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=%E2%98%90%20Other%20,%E2%98%90%20NSAIDS%20%E2%98%90%20Spine%20Injections). Ensuring these fields are completed with sufficient detail (e.g. noting “Low back pain 8 weeks, failed PT and NSAIDs”) is crucial for getting an approval.

## 3\. Data Examples for a Kaggle Demo – Forms, Notes, and Policy Text

For a public Kaggle hackathon demonstration, we can leverage **both template documents and synthetic clinical data** to simulate the prior auth process:

* **Blank or Template PA Forms:** There are publicly available prior authorization form templates (often released by state regulators or insurers). For example, the **Massachusetts Collaborative Imaging Prior Authorization Form** is available as a PDF[\[11\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=%E2%98%90%20CT%20%E2%98%90%20MRI%20%E2%98%90,CHECK%20ALL%20THAT%20APPLY)[\[15\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=%E2%98%90%20Other%20,%E2%98%90%20NSAIDS%20%E2%98%90%20Spine%20Injections). This standardized form can serve as a UI template in the demo – participants could show how an AI agent fills its fields given some inputs. Using a real template adds realism and ensures all necessary fields are accounted for. Another source of form structure is the national electronic PA standards (X12 278 or FHIR PA templates), but those are complex; a simple PDF form is more tangible for a demo.

* **Synthetic Clinical Notes / EMR Excerpts:** To emulate the provider’s justification, one can create mock clinical notes or referral excerpts describing the patient’s condition. For instance, a synthetic clinic note might read: *“50-year-old male with* *8 weeks* *of worsening low back pain radiating to left leg. No relief with NSAIDs, muscle relaxants, or* *6 weeks of physical therapy. Exam: positive straight leg raise, diminished left Achilles reflex. No bowel/bladder issues.”* This kind of narrative contains the key elements (duration, treatments tried, findings, absence of red flags) that an AI would need to extract for the PA request. **De-identified real notes** from open datasets (like MIMIC-IV) could also be used, but generating a few realistic synthetic cases is often simpler and avoids any privacy concerns. The notes can be paired with pre-filled fields (e.g. an ICD-10 code) to simulate the end-to-end scenario of going from unstructured text to a structured PA submission.

* **Payer Policy Text and Criteria:** Including snippets of **official clinical criteria** (from payer policy bulletins or guidelines) in the demo can help the AI justify its decisions. Many payers publish their policy guidelines for imaging. For example, Aetna’s Clinical Policy Bulletin on spine MRI is public, as are others like eviCore’s guidelines or AIM Specialty Health criteria. These can be quoted or referenced in the demo to show the standard (“e.g. **Policy states: MRI is only approved after 6 weeks conservative therapy unless red flags**”). By using such text (which is public domain or freely accessible), a demo could show an **“evidence lookup”** feature – where the AI pulls the relevant line from a policy to explain why it is approving or denying a request. This improves transparency. For instance, eviCore’s 2025 spine imaging guideline explicitly notes the 6-week rule and its red-flag exception[\[2\]](https://www.evicore.com/sites/default/files/clinical-guidelines/2024-11/Cigna_Spine%20Imaging%20Guidelines_V1.1.2025_Eff02.14.2025_pub11.27.2024.pdf#:~:text=Multiple%20studies%20have%20shown%20most,rate%20of%20imaging%20with%20the), and an AI could cite that as evidence in its output.

* **Synthetic PA Records or Tabular Data:** In addition to narrative notes, one might create a small dataset of mock PA requests in structured form, to simulate a database or to evaluate classification. There is precedent for using **simulated prior auth data** in challenges – for example, a 2021 project with CoverMyMeds generated **over one million synthetic pharmacy PA records** for analysis[\[16\]](https://github.com/domagal9/classifymymeds#:~:text=The%20simulated%20dataset%20was%20a,Roughly%20half%20of). In their dataset, each entry included fields like whether the patient had the correct diagnosis, whether they tried alternative medications, and if the PA was approved[\[17\]](https://github.com/domagal9/classifymymeds#:~:text=Prior%20authorization%20information%20is%20available,was%20favorably%20reviewed%20and%20approved). For our imaging context, we could similarly generate a table of cases: e.g. columns for “ConservativeTherapyDuration”, “HasRedFlags”, “PA\_Approved” etc. While we likely won’t have that many records in a hackathon, even a small synthetic table could be used to train/evaluate a simple classifier (or to drive rule-based evaluation).

* **Public Domain Resources:** Tools like **Synthea** (MITRE’s synthetic patient generator) can produce entire fake patient histories (with conditions, encounters, etc.) which could be mined for relevant scenarios[\[18\]](https://mitre.github.io/fhir-for-research/modules/synthea-overview#:~:text=Synthea%20is%20a%20synthetic%20data,not%20real%2C%20synthetic%20electronic). Also, NICE/NHS guidelines (being open access) can provide international policy text for variety. Any data used should be de-identified or synthetic. Kaggle demo data can thus comprise: **a few sample PA request forms, 5–10 mock clinical notes or EMR summaries, and snippets from policy PDFs** – all compiled in a way that participants (or the AI system) can use to extract and cross-reference information.

By combining these elements, the hackathon demo can simulate a realistic prior auth scenario: the AI reads a **clinical note**, checks **policy criteria text**, and populates a **PA form** (or JSON) with evidence. This approach ensures the demo content is **safe and shareable** (no real PHI) while remaining true to real-world prior authorization processes.

## 4\. AI-Powered Prior Authorization Tools – Competitors and Differentiation

In recent years, several companies have launched **AI-driven prior authorization solutions**. Below is a short list of notable tools and their functionalities, along with how a Kaggle demo project could differentiate itself:

### Availity **AuthAI**

**Availity** (a major health information network) offers *AuthAI*, part of its intelligent utilization management platform. AuthAI focuses on **automating PA determinations for payers**. It ingests the clinical data from a request and applies the insurer’s own **medical policy rules** to generate an approval recommendation in real-time[\[19\]](https://www.availity.com/intelligentum/#:~:text=Availity%20AuthAI%20uses%20clinical%20data,helping%20clinicians%20make%20confident%20decisions%E2%80%94faster)[\[20\]](https://www.availity.com/intelligentum/#:~:text=Availity%20AuthAI%20delivers%20authorization%20recommendations,than%2090%20seconds%20on%20average). A key point is that AuthAI is **not a black box model** – it’s described as using *“transparent, policy-based AI”* rather than unconstrained machine learning[\[21\]](https://www.availity.com/intelligentum/#:~:text=Availity%20AuthAI%20uses%20clinical%20data,helping%20clinicians%20make%20confident%20decisions%E2%80%94faster). The system requires that the PA submission include necessary clinical info up front, enabling many requests to get instant automated recommendations (often in under 90 seconds)[\[22\]](https://www.availity.com/intelligentum/#:~:text=). For complex cases, it doesn’t auto-decide but instead **surfaces the most relevant data** to human reviewers in an organized format[\[23\]](https://www.availity.com/intelligentum/#:~:text=determinations,helping%20clinicians%20make%20confident%20decisions%E2%80%94faster)[\[24\]](https://www.availity.com/intelligentum/#:~:text=health%20plan%20remains%20in%20control,helping%20clinicians%20make%20confident%20decisions%E2%80%94faster). Availity emphasizes compliance with new CMS rules (using FHIR APIs for coverage requirements, documentation templates, etc.) and highlights that their AI provides **traceability** by showing which policy criteria matched in each case[\[25\]](https://www.availity.com/intelligentum/#:~:text=Does%20Availity%20AuthAI%20use%20Generative,GenAI)[\[26\]](https://www.availity.com/intelligentum/#:~:text=Availity%20AuthAI%20%E2%80%9Cshows%20its%20work%E2%80%9D,visually%20organized%20for%20easy%20access).

*How a Kaggle project could differ:* AuthAI is a closed commercial system; a hackathon project could demonstrate similar real-time decision support but in a more open, **explainable** way to the end-user. For example, the Kaggle demo could show a visual “checklist” of criteria met/not met for a sample case, with evidence from the input and policy – something AuthAI does behind the scenes with CQL (Clinical Quality Language) but isn’t publicly visible[\[26\]](https://www.availity.com/intelligentum/#:~:text=Availity%20AuthAI%20%E2%80%9Cshows%20its%20work%E2%80%9D,visually%20organized%20for%20easy%20access). The project could focus on **evidence tracing and explainability** (“why was this approved?”) as a core feature, whereas AuthAI’s inner workings are proprietary (even if transparent to the payer). Additionally, unlike AuthAI which avoids generative AI, a Kaggle solution might explore a hybrid approach (LLM to extract info, but rule-based logic to decide) and explicitly handle **uncertainty** by flagging missing info rather than forcing a decision.

### CoverMyMeds **(IntelligentPA)**

**CoverMyMeds** is known for electronic prior auth (ePA) in the pharmacy space. Their platform connects providers, pharmacies, and payers to submit PA requests digitally (largely replacing paper/fax forms for medications). They have introduced *IntelligentPA*, which uses AI/automation to **proactively initiate PA requests** and streamline the workflow in pharmacies[\[27\]](https://info.covermymeds.com/ipa/#:~:text=IntelligentPA%20automatically%20initiates%20a%20request,required%20based%20on%20historical%20data)[\[28\]](https://info.covermymeds.com/ipa/#:~:text=Step%202). For example, if a pharmacy claim is rejected and likely needs a PA, the system waits \~10 minutes for any quick fixes, then auto-starts a PA process and notifies the prescribing provider electronically[\[28\]](https://info.covermymeds.com/ipa/#:~:text=Step%202)[\[29\]](https://info.covermymeds.com/ipa/#:~:text=,manually%20start%20a%20PA%20request). CoverMyMeds thus reduces the manual steps to get a PA started and filled out by pulling data from pharmacy systems and prompting providers as needed. The focus is on **speed and integration** – fitting into the pharmacist’s and provider’s existing systems so that many PAs are resolved within minutes, and communication is improved (providers learn about denials sooner)[\[29\]](https://info.covermymeds.com/ipa/#:~:text=,manually%20start%20a%20PA%20request).

*How a Kaggle project could differ:* CoverMyMeds is largely about **transactional efficiency** (fast initiation, standardized data exchange) rather than deeply analyzing clinical content for appropriateness. A Kaggle demo in the imaging realm could differentiate by showcasing an AI that not only transmits requests but also **intelligently assesses clinical justification**. For instance, the project could highlight how an AI agent reads a clinical note to auto-populate the PA form (including nuanced details like duration of therapy and red flags), whereas CoverMyMeds’ pharmacy solution typically deals with structured fields (e.g., “trial of generic drug \= yes/no”). In essence, the demo could add value with **natural language understanding and evidence checking** – demonstrating capabilities like explaining *why* a PA is needed or suggesting if a PA might not meet criteria (which CoverMyMeds doesn’t explicitly do in the UI). Moreover, the Kaggle project could emphasize **cross-payer policy reasoning** (imagine a system that knows Aetna vs. Cigna criteria differences), whereas CoverMyMeds primarily ensures the request is sent to the right place but doesn’t explain policy details to the user.

### Surescripts **Electronic & Touchless Prior Auth**

**Surescripts** operates a nationwide e-prescribing and health information network, and they offer **electronic prior authorization (EPA)** services, mainly for medications. Their newer *“Touchless Prior Authorization”* aims for fully automated medication PAs by **matching EHR clinical data to the payer’s criteria**. Essentially, Surescripts has integrations where, when a prescriber orders a drug that needs PA, the system can automatically pull required clinical information from the electronic health record and answer the payer’s questions **without provider intervention**, getting an instant decision in many cases[\[30\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=goals%2C%20triggering%20delays%20and%20frustration)[\[31\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=Touchless%20Prior%20Authorization%20matches%20clinical,PBM). They reported a median approval time as low as \~22 seconds for certain meds, with significantly fewer denials and appeals in pilot tests[\[32\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=When%20prior%20authorization%20requirements%20are,appropriate%20medications%20quickly%20and%20seamlessly). The approach relies on a shared standard questionnaire: if the patient’s data in the EHR satisfies all the PBM’s criteria (for example, diagnosis, previous medication trials, lab results), the approval returns automatically[\[33\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=Touchless%20Prior%20Authorization%20matches%20clinical,PBM)[\[34\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=%23%23%23%20Gain%20speed%20with%20built,intelligence). If something is missing, the prescriber is prompted to supply the info via their EHR interface[\[35\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=,to%20complete%20the%20question%20set). Surescripts highlights the benefit to **workflow (inside the EHR)** and **patient experience** (less waiting for meds)[\[36\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=,workflow)[\[34\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=%23%23%23%20Gain%20speed%20with%20built,intelligence). It’s essentially an end-to-end integration of clinical data retrieval, rule application, and X12/FHIR transaction with the PBM.

*How a Kaggle project could differ:* Surescripts’ solution is currently medication-focused and works when the criteria are well-defined and data can be fetched from structured EHR fields. An imaging prior auth demo could borrow the “touchless” concept but apply it to unstructured data – e.g., **using NLP to extract from a doctor’s note** what Surescripts would pull from discrete fields. The Kaggle project could show how an LLM or an agent might parse free text (symptoms, prior treatments) and answer policy criteria, thereby simulating what Surescripts does via direct EHR queries. Additionally, the project could emphasize **explainability and cross-checking**: for example, presenting a checklist (“Criteria X met: Yes – found ‘6 weeks of therapy’ in notes”) with source references, which Surescripts likely handles behind the scenes without showing to the end-user. Finally, the hackathon demo could broaden scope to **medical services PAs (imaging, procedures)** where criteria are more narrative, whereas Surescripts primarily tackles pharmacy PAs with fairly standardized data points.

### Olive AI

**Olive** was a prominent healthcare RPA/AI company that developed automation solutions for revenue cycle and prior auth. Olive’s prior authorization product worked on both the **provider side and the payer side**. For providers, Olive’s AI integrates with the hospital’s EMR to **identify when an order requires prior auth, gather the necessary info, and submit the request electronically**[\[37\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=Seamlessly%20connected%20to%20provider%20EHR,clinical%20documentation%20from%20the%20EHR)[\[38\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=For%20Providers%3A%20Olive%20relieves%20health,across%20all%20types%20of%20prior). This includes pulling documents from the chart, attaching them, and even handling follow-ups or appeals for denied claims[\[39\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=For%20Providers%3A%20Olive%20relieves%20health,over%20your%20prior%20authorization%20task). Olive marketed that it gives health systems a full view of all auth requests and improves approval rates by ensuring medical necessity info is complete[\[38\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=For%20Providers%3A%20Olive%20relieves%20health,across%20all%20types%20of%20prior)[\[40\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=automates%20the%20entire%20end,necessity%20review%20and%20clinical%20documents). On the payer side, Olive can interface with the payer’s criteria and provide **“point-of-care decisions”** if a provider using Olive is in-network: essentially the system checks the request against the payer’s rules in real-time and can return an immediate decision at the point of care[\[41\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=Here%E2%80%99s%20how%20it%20works%3A%20With,machine%20and%20connecting%20providers%20and)[\[42\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=the%20EHR%20for%20your%20members,and%20payers%20with%20unparalleled%20data). Olive thus tried to connect providers and payers on a unified platform, automating the entire lifecycle (it supported standard transactions like the X12 278 authorization request and 275 attachments)[\[42\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=the%20EHR%20for%20your%20members,and%20payers%20with%20unparalleled%20data). In summary, Olive’s solution aimed to **eliminate fax/manual work** by acting as a smart intermediary: it *“automatically initiates PAs, retrieves payer rules, and submits clinical documentation from the EHR”*[\[43\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=Olive%E2%80%99s%20AI,authorizations).

*How a Kaggle project could differ:* Olive’s approach was comprehensive, but one critique of many such systems (and a reason Olive faced headwinds) is the opacity of the AI decision-making and the heavy integration required. A hackathon project can differentiate by focusing on a **lightweight, explainable agent** – one that a user can interact with in a demo without needing full hospital integration. For instance, the Kaggle demo could show a conversational agent that explains to a clinician: “I have gathered that the patient has tried X, Y, Z treatments and still has pain; according to Payer ABC’s policy criterion 1.2, this satisfies the requirement of 6 weeks conservative therapy[\[1\]](https://www.aetna.com/cpb/medical/data/200_299/0236.html#:~:text=malignant%29%3B%C2%A0or%20,deficit%2C%20or%20major%20motor%20weakness%3B%C2%A0or). I will now populate the PA request.” This level of **transparency and justification** is something a user can see, whereas Olive’s system worked behind the scenes. Additionally, the Kaggle project could highlight **modularity and safety** (e.g., the agent knows when to abstain or defer to human if criteria aren’t clear), whereas Olive’s pitch was end-to-end automation – sometimes perceived as a “black box” handling critical tasks. In short, the hackathon project can carve a niche by showcasing **evidence-driven AI with user-facing explanations** and a fail-safe design, which sets it apart from existing commercial offerings that prioritize automation speed but may not expose their reasoning.

## 5\. MVP Architecture and Evaluation Plan for the Hackathon Project

Designing an MVP (Minimum Viable Product) for an **“agentic” prior authorization assistant** requires balancing complexity with hackathon feasibility. Below is a proposed pipeline architecture and an evaluation approach, aligned to Kaggle hackathon constraints (limited time, resources, and need for clear judging criteria):

**Proposed System Architecture:**

1. **Input Ingestion:** The system will accept input such as a *clinical note* (unstructured text) and the *intended imaging order* (e.g., “Lumbar spine MRI”). In a simplified demo, this could be a JSON or form input containing key patient info, the proposed CPT code, and a free-text clinical summary from the doctor.

2. **Evidence Extraction (NLP Agent):** An NLP component (which could be a fine-tuned language model or a rules-based parser) processes the clinical note to extract relevant facts needed for the PA. For example, it would identify **duration of symptoms** (“8 weeks”), **prior treatments tried** (“NSAIDs, physical therapy”), and **presence or absence of red flags** (“no bowel/bladder dysfunction,” “moderate weakness in left foot”). This step yields a structured representation of the case, e.g.:

* { "duration\_weeks": 8, "conservative\_treatments": \["NSAIDs","PT"\],   
    "red\_flag\_present": false, "neuro\_deficit": "mild weakness L5", ... }

* Additionally, the agent could query a **knowledge base of payer criteria** relevant to the requested test. For instance, it might retrieve the policy snippet for “Lumbar MRI” from a stored library (Aetna, Cigna, etc.) to see what the requirements are. This knowledge retrieval ensures the agent knows the rules to check against (e.g., *“if \<6 weeks of therapy AND no red flags \=\> do not approve”*).

3. **Decision Logic & Packet Assembly:** Using the extracted patient evidence and the policy rules, the system makes a determination or at least compiles the **prior authorization packet**. An expert system or simple rule-checker can compare the case data to criteria. For example:

4. If duration\_weeks \>= 6 **OR** red\_flag\_present \== true, then criteria met for imaging.

5. If duration\_weeks \< 6 **AND** no urgent indication, criteria not met (needs more conservative care).  
   In an MVP, we might implement these as straightforward if/else conditions or a decision table derived from the policy. The output of this step would be a structured **PA request** (possibly in JSON form), containing all required fields and an **approval recommendation**. For instance:

* { "Patient": {...}, "Study": "Lumbar MRI", "Indication": "Radiculopathy, no improvement 8 weeks",  
    "MeetsCriteria": true, "MissingInfo": \[\], "Decision": "Recommend Approve" }

* Alongside the fields, the agent can attach **evidence strings** – e.g., quotes from the note (“‘...8 weeks of back pain…’”) and quotes from the policy (“‘MRI indicated after 6 weeks failed conservative therapy’”) to justify each field. Essentially, this is the **checklist generation**: each requirement (duration, prior treatment, etc.) becomes a checkbox in the output, marked yes/no with supporting text.

6. **Output JSON / UI Rendering:** The final output could be a JSON as above (suitable for programmatic evaluation), and/or a human-readable UI. For the demo, one could render a web UI that looks like a filled PA form or a summary page: e.g., “**Approved**: Yes. **Reason**: Patient had 8 weeks of therapy (≥6 weeks required) and no red flags. See evidence below.” Then listing each piece of evidence with citations from the note and policy. If criteria are not met, the UI might highlight which condition failed (e.g., “Not Approved: Only 2 weeks of conservative treatment – policy requires 6 weeks[\[44\]](https://www.evicore.com/sites/default/files/clinical-guidelines/2025-02/EviCore_Spine%20Imaging%20Guidelines_V1.1.2025_Eff02.14.2025_pub11.26.2024_upd02.04.25_0.pdf#:~:text=Multiple%20studies%20have%20shown%20most,rate%20of%20imaging%20with%20the)”). The UI can also emphasize **provenance** by linking each statement to the source (e.g., hover text or footnote showing the policy reference).

7. **Safety and Overrides:** Throughout the pipeline, simple **safety checks** will ensure the agent doesn’t overreach. For instance, if the note is ambiguous or a required field cannot be extracted with confidence, the system should refrain from guessing. Instead, it could mark MissingInfo: \["Unable to determine duration of therapy"\] and the output would then recommend human review (abstention) for that case. The agent will also be constrained to **only use the provided knowledge base** for criteria – this avoids hallucinating any medical guidelines. By structuring it as an extraction \+ rule system, we reduce the chance of the AI making unsupported claims. Any free-text generation (like summarizing a justification) would be kept minimal and always backed by retrieved evidence to maintain reliability.

**Safety Posture:** The MVP will adopt a **conservative stance** appropriate for medical AI. Concretely, this means: \- **No unsupported approvals or denials** – if the data is insufficient or uncertain, the agent will default to saying *“Unable to determine – escalate to a human”* rather than risk an incorrect decision. This could be implemented as a threshold on confidence scores from the NLP extractor or simply presence of critical fields.  
\- **No patient-identifiable data in outputs** – since we use synthetic or de-identified inputs, this is ensured. The agent will also be instructed not to include any extraneous info beyond the scope (prevent it from, say, revealing an internal prompt or any non-clinical commentary).  
\- **Alignment with Policies** – the agent will always cite actual policy text for each criterion evaluation, ensuring that its reasoning is grounded in accepted guidelines (and not, for example, an outdated or biased heuristic). This traceability is a safety feature that allows verification of the agent’s advice.  
\- **User override** – In a real setting, even if the agent recommends “deny” based on criteria, a clinician should be able to override or provide additional info. In the demo, we can simulate this by showing that the agent flags what’s missing (e.g., “patient has only done 4 weeks of PT – likely insufficient”) and suggesting next steps (“consider continuing conservative care or document exception if warranted”). This shows the AI is a **support tool, not final arbiter**.

**Evaluation Plan & Scoring:** To judge the performance of the system in a hackathon, we propose a rubric that measures both completeness of output and adherence to truth/safety:

* **Completeness & Accuracy (40%):** Does the system correctly fill in all the key fields and checklist items for the prior authorization? Each test case (which has a known ground-truth outcome) can be scored for correct identification of elements like duration of therapy, presence of red flags, etc. For example, if a case should meet criteria, the system should output MeetsCriteria:true and the appropriate justifications. Partial credit can be given if it catches some but not all criteria. A quantitative measure could be F1-score or accuracy on a set of binary criteria checks (similar to how one would score an information extraction task).

* **Provenance & Justification (25%):** The solution should provide evidence for its decisions. Judges will check if **citations or references** are present for each major claim (e.g., “6 weeks of therapy” should be backed by either the note text or a reference in the input; “required by policy” should have a footnote to the policy source). A response that simply says “Approved” with no explanation would score low, whereas one that says “Approved because X criterion met (source: policy PDF line Y, patient record line Z)” scores high. This encourages **explainability**. We can operationalize this by requiring, for instance, a certain format of output where evidence strings are attached – and then verifying their presence.

* **Alignment & Safety (20%):** This covers whether the system’s decision logic aligns with known policies (no hallucinated criteria) and whether it refrains from hazardous guesses. Cases with deliberately incomplete information can test the abstention behavior. If a system appropriately says “Information not sufficient to decide” in those cases, it should get a high score for safety/uncertainty handling. Conversely, if it makes up an answer or uses incorrect criteria, it would be penalized. Judges might have a few “edge” scenarios to see if the AI appropriately defers (for example, a note that doesn’t state duration at all – the expected correct behavior is to flag this, not assume it’s been met).

* **Innovation (15%):** Although subjective, part of the hackathon scoring can reward how novel or user-friendly the solution is. For instance, a slick UI that highlights the checklist of criteria with green/red marks could impress judges. Or the use of modern techniques (like a lightweight transformer model for NLP that’s fine-tuned on clinical text) might be noted. This category ensures teams don’t just hard-code everything – some sophistication and generalizability are encouraged. That said, even the most innovative solution must still be grounded in correctness and safety as above.

Using this rubric, the MVP will be evaluated on both its technical performance and its compliance with the needs of prior authorization. The end goal is a demo that convincingly shows how AI can automate PA **with transparency**. Success means demonstrating that the agent can produce a comprehensive PA request (or a decision recommendation) that a clinician and a payer would both trust – because every data point is filled, every claim is backed by evidence, and no step defies the given guidelines. Such a solution, while simplified for Kaggle, would illustrate a pathway to making prior authorizations faster and more reliable, ultimately reducing the burden on healthcare providers.

**Sources:** Official clinical policy and guideline documents (Aetna CPB, eviCore/Cigna criteria, NHS guidance), standard PA form templates, and vendor product literature were referenced to ensure real-world accuracy[\[1\]](https://www.aetna.com/cpb/medical/data/200_299/0236.html#:~:text=malignant%29%3B%C2%A0or%20,deficit%2C%20or%20major%20motor%20weakness%3B%C2%A0or)[\[6\]](https://www.coventryrugbygpgateway.nhs.uk/pages/management-of-neck-back-pain/#:~:text=Do%20NOT%20offer%20r%20outine,the%20absence%20of%20red%20flags)[\[13\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=Check%20One%20,Exercise%20Program%20%E2%98%90%20Physical%20Therapy)[\[19\]](https://www.availity.com/intelligentum/#:~:text=Availity%20AuthAI%20uses%20clinical%20data,helping%20clinicians%20make%20confident%20decisions%E2%80%94faster)[\[37\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=Seamlessly%20connected%20to%20provider%20EHR,clinical%20documentation%20from%20the%20EHR). These sources are cited in-line above, and they provide further detail on specific criteria and system capabilities as discussed.

---

[\[1\]](https://www.aetna.com/cpb/medical/data/200_299/0236.html#:~:text=malignant%29%3B%C2%A0or%20,deficit%2C%20or%20major%20motor%20weakness%3B%C2%A0or) [\[3\]](https://www.aetna.com/cpb/medical/data/200_299/0236.html#:~:text=,location%20for%20performing%20the%20injection%3B%C2%A0or) Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) of the Spine \- Medical Clinical Policy Bulletins | Aetna

[https://www.aetna.com/cpb/medical/data/200\_299/0236.html](https://www.aetna.com/cpb/medical/data/200_299/0236.html)

[\[2\]](https://www.evicore.com/sites/default/files/clinical-guidelines/2024-11/Cigna_Spine%20Imaging%20Guidelines_V1.1.2025_Eff02.14.2025_pub11.27.2024.pdf#:~:text=Multiple%20studies%20have%20shown%20most,rate%20of%20imaging%20with%20the) Cigna Spine Imaging Guidelines \- V1.1.2025 \- Effective 02/14/2025

[https://www.evicore.com/sites/default/files/clinical-guidelines/2024-11/Cigna\_Spine%20Imaging%20Guidelines\_V1.1.2025\_Eff02.14.2025\_pub11.27.2024.pdf](https://www.evicore.com/sites/default/files/clinical-guidelines/2024-11/Cigna_Spine%20Imaging%20Guidelines_V1.1.2025_Eff02.14.2025_pub11.27.2024.pdf)

[\[4\]](https://www.mcg.com/blog/cms-appropriate-use-criteria-auc-imaging/#:~:text=First%20established%20by%20the%20Protecting,a%20Medicare%20beneficiary%20would%20be) [\[5\]](https://www.mcg.com/blog/cms-appropriate-use-criteria-auc-imaging/#:~:text=An%20Indefinite%20Pause%20on%20AUC) CMS Pauses Appropriate Use Criteria (AUC) Program for Advanced Diagnostic Imaging | MCG

[https://www.mcg.com/blog/cms-appropriate-use-criteria-auc-imaging/](https://www.mcg.com/blog/cms-appropriate-use-criteria-auc-imaging/)

[\[6\]](https://www.coventryrugbygpgateway.nhs.uk/pages/management-of-neck-back-pain/#:~:text=Do%20NOT%20offer%20r%20outine,the%20absence%20of%20red%20flags) Low Back Pain – GP Gateway

[https://www.coventryrugbygpgateway.nhs.uk/pages/management-of-neck-back-pain/](https://www.coventryrugbygpgateway.nhs.uk/pages/management-of-neck-back-pain/)

[\[7\]](https://bsw.icb.nhs.uk/wp-content/uploads/sites/6/2023/09/BSW-ICB-CP039-Spinal-pain-Neck-and-lower-back.pdf#:~:text=or%20back%20pain%20with%20radiculopathy,OR) bsw.icb.nhs.uk

[https://bsw.icb.nhs.uk/wp-content/uploads/sites/6/2023/09/BSW-ICB-CP039-Spinal-pain-Neck-and-lower-back.pdf](https://bsw.icb.nhs.uk/wp-content/uploads/sites/6/2023/09/BSW-ICB-CP039-Spinal-pain-Neck-and-lower-back.pdf)

[\[8\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=SECTION%201,Name%3A%20Facility%20Tax%20ID%3A%20NPI) [\[9\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=SECTION%202,EXAM%20REQUEST) [\[10\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=Phone%20,EXAM%20REQUEST) [\[11\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=%E2%98%90%20CT%20%E2%98%90%20MRI%20%E2%98%90,CHECK%20ALL%20THAT%20APPLY) [\[12\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=%E2%98%90%20SPINE%20%E2%98%90%20Neurological%20Deficits,ray) [\[13\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=Check%20One%20,Exercise%20Program%20%E2%98%90%20Physical%20Therapy) [\[14\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=implants%2C%20for%20detection%20of%20implant,birads3) [\[15\]](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf#:~:text=%E2%98%90%20Other%20,%E2%98%90%20NSAIDS%20%E2%98%90%20Spine%20Injections) Aetna \- CT/CTA/MRI/MRA Prior Authorization Form \- State of Massachusetts

[https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf](https://www.aetna.com/content/dam/aetna/pdfs/aetnacom/healthcare-professionals/documents-forms/ma-ct-cta-mri-mra-prior-auth-form.pdf)

[\[16\]](https://github.com/domagal9/classifymymeds#:~:text=The%20simulated%20dataset%20was%20a,Roughly%20half%20of) [\[17\]](https://github.com/domagal9/classifymymeds#:~:text=Prior%20authorization%20information%20is%20available,was%20favorably%20reviewed%20and%20approved) GitHub \- domagal9/classifymymeds: ClassifyMyMeds: Predicting Prior Authorization Approval and Volume for CoverMyMeds

[https://github.com/domagal9/classifymymeds](https://github.com/domagal9/classifymymeds)

[\[18\]](https://mitre.github.io/fhir-for-research/modules/synthea-overview#:~:text=Synthea%20is%20a%20synthetic%20data,not%20real%2C%20synthetic%20electronic) Synthea Synthetic Data Overview – FHIR® for Research ...

[https://mitre.github.io/fhir-for-research/modules/synthea-overview](https://mitre.github.io/fhir-for-research/modules/synthea-overview)

[\[19\]](https://www.availity.com/intelligentum/#:~:text=Availity%20AuthAI%20uses%20clinical%20data,helping%20clinicians%20make%20confident%20decisions%E2%80%94faster) [\[20\]](https://www.availity.com/intelligentum/#:~:text=Availity%20AuthAI%20delivers%20authorization%20recommendations,than%2090%20seconds%20on%20average) [\[21\]](https://www.availity.com/intelligentum/#:~:text=Availity%20AuthAI%20uses%20clinical%20data,helping%20clinicians%20make%20confident%20decisions%E2%80%94faster) [\[22\]](https://www.availity.com/intelligentum/#:~:text=) [\[23\]](https://www.availity.com/intelligentum/#:~:text=determinations,helping%20clinicians%20make%20confident%20decisions%E2%80%94faster) [\[24\]](https://www.availity.com/intelligentum/#:~:text=health%20plan%20remains%20in%20control,helping%20clinicians%20make%20confident%20decisions%E2%80%94faster) [\[25\]](https://www.availity.com/intelligentum/#:~:text=Does%20Availity%20AuthAI%20use%20Generative,GenAI) [\[26\]](https://www.availity.com/intelligentum/#:~:text=Availity%20AuthAI%20%E2%80%9Cshows%20its%20work%E2%80%9D,visually%20organized%20for%20easy%20access) AI-Powered Prior Authorization | Healthcare | Availity

[https://www.availity.com/intelligentum/](https://www.availity.com/intelligentum/)

[\[27\]](https://info.covermymeds.com/ipa/#:~:text=IntelligentPA%20automatically%20initiates%20a%20request,required%20based%20on%20historical%20data) [\[28\]](https://info.covermymeds.com/ipa/#:~:text=Step%202) [\[29\]](https://info.covermymeds.com/ipa/#:~:text=,manually%20start%20a%20PA%20request) CoverMyMeds Prior Authorization Software

[https://info.covermymeds.com/ipa/](https://info.covermymeds.com/ipa/)

[\[30\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=goals%2C%20triggering%20delays%20and%20frustration) [\[31\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=Touchless%20Prior%20Authorization%20matches%20clinical,PBM) [\[32\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=When%20prior%20authorization%20requirements%20are,appropriate%20medications%20quickly%20and%20seamlessly) [\[33\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=Touchless%20Prior%20Authorization%20matches%20clinical,PBM) [\[34\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=%23%23%23%20Gain%20speed%20with%20built,intelligence) [\[35\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=,to%20complete%20the%20question%20set) [\[36\]](https://surescripts.com/what-we-do/touchless-prior-authorization#:~:text=,workflow) Touchless Prior Authorization | Surescripts

[https://surescripts.com/what-we-do/touchless-prior-authorization](https://surescripts.com/what-we-do/touchless-prior-authorization)

[\[37\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=Seamlessly%20connected%20to%20provider%20EHR,clinical%20documentation%20from%20the%20EHR) [\[38\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=For%20Providers%3A%20Olive%20relieves%20health,across%20all%20types%20of%20prior) [\[39\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=For%20Providers%3A%20Olive%20relieves%20health,over%20your%20prior%20authorization%20task) [\[40\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=automates%20the%20entire%20end,necessity%20review%20and%20clinical%20documents) [\[41\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=Here%E2%80%99s%20how%20it%20works%3A%20With,machine%20and%20connecting%20providers%20and) [\[42\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=the%20EHR%20for%20your%20members,and%20payers%20with%20unparalleled%20data) [\[43\]](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview#:~:text=Olive%E2%80%99s%20AI,authorizations) Olive's Prior Authorization Solution

[https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview](https://marketplace.microsoft.com/en-us/product/saas/oliveaiinc1611094638883.draft?tab=overview)

[\[44\]](https://www.evicore.com/sites/default/files/clinical-guidelines/2025-02/EviCore_Spine%20Imaging%20Guidelines_V1.1.2025_Eff02.14.2025_pub11.26.2024_upd02.04.25_0.pdf#:~:text=Multiple%20studies%20have%20shown%20most,rate%20of%20imaging%20with%20the) EviCore Spine Imaging Guidelines \- V1.1.2025 \- Effective 02/14/2025

[https://www.evicore.com/sites/default/files/clinical-guidelines/2025-02/EviCore\_Spine%20Imaging%20Guidelines\_V1.1.2025\_Eff02.14.2025\_pub11.26.2024\_upd02.04.25\_0.pdf](https://www.evicore.com/sites/default/files/clinical-guidelines/2025-02/EviCore_Spine%20Imaging%20Guidelines_V1.1.2025_Eff02.14.2025_pub11.26.2024_upd02.04.25_0.pdf)
